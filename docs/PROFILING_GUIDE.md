# Diffusion Model Compute Profiling Guide

## Introduction

This guide documents the implementation of architecture-aware MACs profiling for diffusion models, achieved by analyzing the diffusers library source code.

## Overview

The profiler calculates MACs (Multiply-Accumulate Operations) for each component of a diffusion model:

- Transformer/UNet (per denoising step)
- Text Encoders (one-time)
- VAE Decoder (one-time)

Total compute is calculated as: `Transformer Ã— steps + Text Encoders + VAE Decoder`

## Supported Architectures

### Fully Supported (7 models tested):

**Flow Matching Models:**

- Stable Diffusion 3 Medium (52.3 TFLOPs for 30 steps)

**DiT (Diffusion Transformer) Models:**

- SANA-1.6B (442.1 TFLOPs)
- SANA-600M (206.5 TFLOPs)
- Lumina-Image-2.0 (155.0 TFLOPs)
- PixArt-XL (42.5 TFLOPs)

**Classic Diffusion Models:**

- Stable Diffusion 2.1-base (36.5 TFLOPs)
- Kandinsky-3 (29.4 TFLOPs)

### Partial Support:

**FLUX Models:**

- Text encoders and VAE profiling works
- Transformer profiling incompatible with thop library (dual-stream attention)
- Alternative: Use analytical calculation or timing-based profiling

## Implementation Details

### Architecture Detection

The profiler automatically detects model architecture from class names:

```python
def _get_model_type(self, model):
    model_class_name = model.__class__.__name__
    if 'SD3' in model_class_name:
        return 'sd3'
    elif 'Sana' in model_class_name or 'PixArt' in model_class_name:
        return 'generic_transformer'
    elif 'Lumina2' in model_class_name:
        return 'lumina2'
    elif 'Kandinsky3' in model_class_name:
        return 'kandinsky3'
    elif 'UNet' in model_class_name:
        return 'unet'
```

### Forward Signature Patterns

Analysis of diffusers source code revealed three main patterns:

**Pattern 1: Keyword Arguments (SD3, FLUX)**

```python
def forward(self, hidden_states=None, encoder_hidden_states=None,
            pooled_projections=None, timestep=None, ...)
```

**Pattern 2: Positional Arguments (SANA, PixArt)**

```python
def forward(self, hidden_states, encoder_hidden_states, timestep, ...)
```

**Pattern 3: Hybrid (Standard UNet, Kandinsky)**

```python
def forward(self, sample, timestep, encoder_hidden_states=None, ...)
```

### Config Parameter Mapping

Different architectures use different config parameter names for the same concept:

| Architecture | Text Embedding Dimension  | VAE Latent Channels |
| ------------ | ------------------------- | ------------------- |
| SD3          | `joint_attention_dim`     | 16                  |
| SANA         | `caption_channels` (2304) | 32                  |
| Lumina2      | `cap_feat_dim` (2304)     | 16                  |
| PixArt       | `cross_attention_dim`     | 4                   |

The profiler implements a fallback chain to detect the correct dimension:

```python
dim = getattr(model.config, 'joint_attention_dim', None)
if dim is None:
    dim = getattr(model.config, 'caption_channels', None)
if dim is None:
    dim = getattr(model.config, 'cap_feat_dim', None)
if dim is None:
    dim = getattr(model.config, 'cross_attention_dim', None)
if dim is None:
    dim = 4096  # Fallback
```

### VAE Latent Channel Handling

VAE latent channels vary across architectures:

- **4 channels**: SD 1.x, 2.x, PixArt
- **16 channels**: SD3, FLUX, Lumina
- **32 channels**: SANA (13.5x more compute)

The profiler reads this dynamically:

```python
latent_channels = getattr(pipe.vae.config, 'latent_channels', 4)
```

## Component Breakdown

### Transformer/UNet Profiling

For each architecture, we create a specific wrapper that matches the forward signature:

**SD3 Example:**

```python
class SD3TransformerWrapper(nn.Module):
    def forward(self, hidden_states):
        return self.transformer(
            hidden_states=hidden_states,
            encoder_hidden_states=self.encoder_hidden_states,
            pooled_projections=self.pooled_projections,
            timestep=self.timestep,
            return_dict=False
        )[0]
```

**Generic Transformer Example (SANA, PixArt):**

```python
class GenericTransformerWrapper(nn.Module):
    def forward(self, hidden_states):
        return self.transformer(
            hidden_states,  # Positional
            self.encoder_hidden_states,  # Positional
            self.timestep,  # Positional
            return_dict=False
        )[0]
```

### Text Encoder Profiling

Text encoders are profiled independently for each encoder in multi-encoder setups:

- SD3 has 3 encoders: CLIP-L, CLIP-G, T5-XXL
- SDXL has 2 encoders: CLIP-L, CLIP-G
- Most models have 1 encoder: CLIP or T5

Total text encoder MACs = sum of all encoders (conditional + unconditional passes)

### VAE Decoder Profiling

VAE decoder is profiled once with the correct latent channel count:

```python
latent_channels = getattr(pipe.vae.config, 'latent_channels', 4)
latents = torch.randn(1, latent_channels, H//8, W//8)
```

## Adding Support for New Models

To add support for a new architecture:

1. **Find the forward signature** in diffusers source code
2. **Create a wrapper class** that matches the signature
3. **Add model type detection** in `_get_model_type()`
4. **Test with the model**

Example for a hypothetical new architecture:

```python
# Step 1: Check diffusers source for forward signature
# Found: def forward(self, x, t, context, mask)

# Step 2: Create wrapper
class NewArchWrapper(nn.Module):
    def __init__(self, model, context, mask, timestep):
        super().__init__()
        self.model = model
        self.context = context
        self.mask = mask
        self.timestep = timestep

    def forward(self, x):
        return self.model(x, self.timestep, self.context, self.mask, return_dict=False)[0]

# Step 3: Add detection
def _get_model_type(self, model):
    if 'NewArch' in model.__class__.__name__:
        return 'new_arch'
    # ... existing conditions

# Step 4: Use wrapper in measure_unet_macs()
elif model_type == 'new_arch':
    wrapper = NewArchWrapper(model, context, mask, timestep).to(device)
```

## Results Summary

Computational requirements for 512x512 generation with 30 steps:

### High Compute Models (>100 TFLOPs):

- SANA-1.6B: 442.1 TFLOPs (transformer: 14.2 TMACs/step)
- SANA-600M: 206.5 TFLOPs (transformer: 6.3 TMACs/step)
- Lumina-Image-2.0: 155.0 TFLOPs (transformer: 5.1 TMACs/step)

### Medium Compute Models (40-60 TFLOPs):

- SD3-medium: 52.3 TFLOPs (transformer: 1.7 TMACs/step)
- PixArt-XL: 42.5 TFLOPs (transformer: 1.4 TMACs/step)

### Low Compute Models (<40 TFLOPs):

- SD2.1-base: 36.5 TFLOPs (UNet: 1.2 TMACs/step)
- Kandinsky-3: 29.4 TFLOPs (UNet: 0.9 TMACs/step)

### Component Contribution:

For all models, the distribution is approximately:

- Transformer/UNet: 95%
- Text Encoders: 2%
- VAE Decoder: 3%

Exception: SANA models have higher VAE contribution (8%) due to 32-channel VAE.

## Technical Insights

### Learned from Diffusers Source Code:

1. **No Universal Forward Signature**

   - Each architecture family has unique parameter ordering
   - Some use keyword arguments, others positional
   - Requires architecture-specific handling

2. **Config Parameter Inconsistency**

   - Same concept has different names across architectures
   - Must implement fallback chain for dimension detection
   - Cannot rely on single config attribute

3. **VAE Architectural Diversity**

   - Latent channels vary: 4, 16, or 32
   - Must be read dynamically from config
   - Dramatically affects compute requirements

4. **Positional Encoding Variations**
   - FLUX uses RoPE with img_ids/txt_ids
   - Lumina uses rotary embeddings
   - SD3 uses learned patch embeddings
   - Standard UNet has no explicit position encoding

### Critical Implementation Decisions:

1. **Wrapper-based approach**: Each architecture gets its own wrapper matching its forward signature
2. **Dynamic dimension detection**: Read from config with fallback chain
3. **Automatic type detection**: Infer from class name to select appropriate wrapper
4. **Component-wise profiling**: Separate profiling for transformer, text encoders, and VAE

## Usage Examples

### Example 1: Profile Multiple Models

```python
models = [
    "stabilityai/stable-diffusion-3-medium-diffusers",
    "Efficient-Large-Model/Sana_600M_512px_diffusers",
    "PixArt-alpha/PixArt-XL-2-512x512"
]

for model_id in models:
    pipe = manager.load_model(model_id)
    summary = profiler.summarize_macs(pipe, height=512, width=512, steps=30)
    print(f"{model_id}: {summary['Total 30 steps (GMACs)']/1000:.1f} TFLOPs")
```

### Example 2: Resolution Scaling

```python
pipe = manager.load_model("stabilityai/stable-diffusion-3-medium-diffusers")

for resolution in [512, 768, 1024]:
    summary = profiler.summarize_macs(
        pipe,
        height=resolution,
        width=resolution,
        steps=30
    )
    print(f"{resolution}x{resolution}: {summary['Total 30 steps (GMACs)']/1000:.1f} TFLOPs")
```

### Example 3: Step Count Scaling

```python
pipe = manager.load_model("Efficient-Large-Model/Sana_600M_512px_diffusers")

for steps in [10, 20, 30, 50]:
    summary = profiler.summarize_macs(pipe, height=512, width=512, steps=steps)
    print(f"{steps} steps: {summary[f'Total {steps} steps (GMACs)']/1000:.1f} TFLOPs")
```

## Known Limitations

### FLUX Transformer:

FLUX's dual-stream attention architecture creates tensor dimension mismatches during profiling. Text encoder and VAE profiling works, but transformer profiling is incompatible with the thop library.

**Workaround:** Use text encoder + VAE as lower bound, or implement analytical calculation based on architecture parameters.

### LuminaNext:

Rotary embedding dimension mismatches occur during profiling. Text encoder and VAE profiling works.

### Models with CPU Offloading:

Models loaded with device_map='auto' may have meta tensors that cannot be profiled. Disable CPU offloading for accurate profiling.

## Performance Notes

### Profiling Overhead:

- Loading model: 10-120 seconds (depending on model size)
- Profiling: 0.3-3 seconds
- Total: Usually under 2 minutes per model

### Memory Requirements:

- Models are loaded to GPU for profiling
- Requires sufficient VRAM for the model
- Memory is freed after profiling completes

## References

### Diffusers Source Files Analyzed:

- `models/transformers/transformer_sd3.py` - SD3 architecture
- `models/transformers/sana_transformer.py` - SANA architecture
- `models/transformers/pixart_transformer_2d.py` - PixArt architecture
- `models/transformers/transformer_lumina2.py` - Lumina2 architecture
- `models/transformers/lumina_nextdit2d.py` - LuminaNext architecture
- `models/unets/unet_kandinsky3.py` - Kandinsky-3 UNet
- `models/transformers/transformer_flux.py` - FLUX architecture
- `models/autoencoders/autoencoder_kl.py` - VAE configurations

### Key Concepts:

**MACs (Multiply-Accumulate Operations)**: Number of multiply-add operations. Commonly used for neural network compute measurement.

**GMACs**: Giga MACs (billions of MACs)

**TFLOPs**: Tera FLOPs (FLOPs â‰ˆ 2 Ã— MACs for most operations)

**DiT**: Diffusion Transformer - transformer-based diffusion models

**Flow Matching**: Alternative to diffusion process using rectified flows

## Troubleshooting

### Profiling Returns Zero:

**Cause**: Forward signature mismatch - wrapper doesn't match actual model forward method.

**Solution**:

1. Check model class name in error message
2. Find corresponding transformer file in diffusers source
3. Check forward method signature
4. Create appropriate wrapper

### Dimension Mismatch Errors:

**Cause**: Incorrect text embedding dimension.

**Solution**:

1. Load model and check `model.config`
2. Find text embedding dimension parameter
3. Add to fallback chain in `_prepare_transformer_inputs()`

### Meta Tensor Errors:

**Cause**: Model has CPU-offloaded parameters.

**Solution**: Load model without device_map or disable CPU offloading.

## Best Practices

1. **Always profile with same resolution**: Different resolutions give different results
2. **Use consistent step count**: Typically 30 or 50 steps
3. **Free memory between models**: Call `torch.cuda.empty_cache()`
4. **Check profiling enabled**: Verify `thop` library is installed
5. **Validate results**: Check that MACs values are non-zero and realistic

## Future Improvements

Potential enhancements:

1. **Analytical FLUX calculation**: Compute MACs from architecture parameters
2. **fvcore profiler**: Alternative to thop for incompatible architectures
3. **Result caching**: Store profiling results to avoid re-profiling
4. **Video model support**: Extend to video diffusion models
5. **Batch size scaling**: Profile with different batch sizes

## Conclusion

By learning from diffusers source code, we implemented an extensible profiling framework that:

- Automatically adapts to different architectures
- Provides accurate component-wise breakdowns
- Handles config parameter inconsistencies
- Supports 8+ architecture families

The wrapper pattern makes adding new architectures straightforward - typically 30 minutes of work to add support for a new model family.
