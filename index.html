<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Image Generation Case Study - Bili-Sakura</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/index.css" />
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Image Generation Case Study
              </h1>
              <h2 class="subtitle is-3">
                A Comprehensive Study of Open-Source Diffusion Models and API Services
              </h2>
              <div class="publication-authors">
                <span class="author-block">
                  <a href="https://github.com/Bili-Sakura">Bili-Sakura</a>
                </span>
              </div>
              <div class="publication-links" style="margin-top: 1rem;">
                <span class="link-block">
                  <a href="https://github.com/Bili-Sakura/image-generation-case-study"
                     class="button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" width="16" height="16">
                        <path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path>
                      </svg>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Abstract -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">About This Project</h2>
            <div class="content has-text-justified">
              <p>
                This repository provides a comprehensive case study of existing open-source diffusion models' 
                capabilities in text-to-image generation and image editing. It offers a unified interface for 
                comparing and experimenting with 14 state-of-the-art text-to-image models, along with support 
                for closed-source API services.
              </p>
              <p>
                Whether you're a researcher exploring the latest in generative AI, a developer integrating 
                image generation into your applications, or an enthusiast experimenting with different models, 
                this project provides an easy-to-use platform for text-to-image generation with comprehensive 
                model support and flexible deployment options.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Key Features -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Key Features</h2>
        <div class="content">
          <ul>
            <li>üé® <strong>Multi-model Comparison</strong>: Generate images with multiple models simultaneously for side-by-side comparison</li>
            <li>üîì <strong>14 Open-Source Models</strong>: Including Stable Diffusion variants, FLUX.1, SDXL, CogView, PixArt, and more</li>
            <li>üîí <strong>Closed-Source API Integration</strong>: Support for OpenAI DALL-E, Google Imagen, Bytedance Cloud, and Kling AI</li>
            <li>üñ•Ô∏è <strong>Gradio Web UI</strong>: User-friendly interface for interactive image generation</li>
            <li>‚öôÔ∏è <strong>Configurable Parameters</strong>: Full control over inference steps, guidance scale, image size, and seed</li>
            <li>üíæ <strong>Auto-save Organization</strong>: Images automatically saved with timestamp folders and generation config JSON</li>
            <li>üöÄ <strong>Multi-GPU Support</strong>: Automatic device mapping for utilizing multiple GPUs efficiently</li>
            <li>üìä <strong>Memory Efficient</strong>: Sequential generation to manage VRAM usage</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Supported Models -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Supported Models</h2>
        <div class="content">
          <h3 class="title is-4">Open-Source Text-to-Image Models (14 Total)</h3>
          <p>From lightweight 3GB models to state-of-the-art 16GB models:</p>
          <div class="columns is-multiline" style="margin-top: 1rem;">
            <div class="column is-half">
              <div class="box">
                <h4 class="title is-5">‚ö° Fast & Efficient</h4>
                <ul>
                  <li><strong>Stable Diffusion 2.1</strong> (~4 GB) - Classic, reliable</li>
                  <li><strong>PixArt-XL 2</strong> (~4 GB) - Fast generation</li>
                  <li><strong>Sana 600M</strong> (~3 GB) - Lightweight</li>
                </ul>
              </div>
            </div>
            <div class="column is-half">
              <div class="box">
                <h4 class="title is-5">üéØ High Quality</h4>
                <ul>
                  <li><strong>Stable Diffusion XL</strong> (~7 GB) - Higher quality</li>
                  <li><strong>FLUX.1 Dev</strong> (~16 GB) - State-of-the-art</li>
                  <li><strong>Stable Diffusion 3</strong> (~9 GB) - Latest SD3</li>
                </ul>
              </div>
            </div>
            <div class="column is-half">
              <div class="box">
                <h4 class="title is-5">üåè Multilingual</h4>
                <ul>
                  <li><strong>CogView3 Plus 3B</strong> (~6 GB) - Multilingual</li>
                  <li><strong>CogView4 6B</strong> (~11 GB) - Latest CogView</li>
                  <li><strong>HunyuanDiT v1.2</strong> (~10 GB) - Chinese + English</li>
                </ul>
              </div>
            </div>
            <div class="column is-half">
              <div class="box">
                <h4 class="title is-5">üî¨ Specialized</h4>
                <ul>
                  <li><strong>Stable Cascade</strong> (~10 GB) - Multi-stage</li>
                  <li><strong>Qwen Image</strong> (~8 GB) - Multimodal</li>
                  <li><strong>UniDiffuser v1</strong> (~5 GB) - Unified model</li>
                </ul>
              </div>
            </div>
          </div>
          
          <h3 class="title is-4" style="margin-top: 2rem;">Closed-Source API Services</h3>
          <div class="content">
            <ul>
              <li><strong>OpenAI DALL-E</strong>: DALL-E 2 & DALL-E 3 with quality and style controls (up to 1792x1792)</li>
              <li><strong>Google Imagen</strong>: Vertex AI Imagen for photorealistic generation (up to 1536x1536)</li>
              <li><strong>Bytedance Cloud</strong>: Volcano Engine text-to-image API (up to 2048x2048)</li>
              <li><strong>Kling AI</strong>: High-quality generation models (up to 2048x2048)</li>
            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- Quick Start -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Quick Start</h2>
        <div class="content">
          <h3 class="title is-4">Installation</h3>
          <pre><code># Clone the repository
git clone https://github.com/Bili-Sakura/image-generation-case-study.git
cd image-generation-case-study

# Install dependencies
pip install -r requirements.txt

# Optional: Install API dependencies for closed-source models
pip install -r requirements_api.txt</code></pre>

          <h3 class="title is-4">Usage</h3>
          <p><strong>Option 1: Gradio Web UI (Recommended)</strong></p>
          <pre><code>python run.py</code></pre>
          <p>This will open a web browser at <code>http://localhost:7860</code> with an intuitive UI for text-to-image generation.</p>
          
          <p><strong>Option 2: Python API</strong></p>
          <pre><code>from src.model_manager import get_model_manager
from src.inference import generate_image

# Load model
manager = get_model_manager()
manager.load_model("stabilityai/stable-diffusion-2-1")

# Generate
image, filepath, seed = generate_image(
    model_id="stabilityai/stable-diffusion-2-1",
    prompt="A fantasy landscape with mountains and rivers",
    num_inference_steps=50,
    guidance_scale=7.5,
    seed=42
)</code></pre>

          <h3 class="title is-4">Generation Parameters</h3>
          <ul>
            <li><strong>Inference Steps</strong>: 10-100 (default: 50) - More steps = higher quality but slower</li>
            <li><strong>Guidance Scale</strong>: 1.0-20.0 (default: 7.5) - Higher values = stronger prompt adherence</li>
            <li><strong>Image Sizes</strong>: 512px to 1280px with multiple presets</li>
            <li><strong>Seed Control</strong>: Fixed seed for reproducibility or random (-1)</li>
            <li><strong>Negative Prompts</strong>: Supported on compatible models</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Citation -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Citation</h2>
        <div class="content">
          <p>If you find this repository useful, please cite it as:</p>
          <pre><code>@misc{bili_sakura_image_generation_case_study,
  author       = {Bili-Sakura},
  title        = {Image Generation Case Study},
  year         = {2025},
  howpublished = {\url{https://github.com/Bili-Sakura/image-generation-case-study}},
  note         = {Accessed: 2025-10-08}
}</code></pre>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content has-text-centered">
              <p>
                This project is maintained by 
                <a href="https://github.com/Bili-Sakura">Bili-Sakura</a>.
              </p>
              <p>
                Source code is available on 
                <a href="https://github.com/Bili-Sakura/image-generation-case-study">
                  <strong>GitHub</strong>
                </a> and licensed under the project's license.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
